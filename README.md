## 博客多标签提取

<简洁介绍文档> 

内容范围: 主要面向使用者的使用与操作说明；

## 最终结果
能够提供以下字段:

博主ID，标签词；计算的时间(得出标签的时间)；


## 技术路线：
有监督的文本多标签模型；
使用ALBERT或者BERT模型训练；


## 所有标签：

目前包含22类标签，标签的对应关系保存在文件`labels_list.txt`中

```
other	其它	0
recreation	娱乐	1
cute	萌宠	2
fashion	时尚	3
music	音乐	4
street	街拍	5
news	新闻	6
live	直播	7
photography	摄影	8
cate	美食	9
travel	旅行	10
fitness	健身	11
beauty	美妆	12
sign 	星座	13
life	生活	14
girl	小姐姐	15
emotion	情感	16
car	汽车	17
brother	小哥哥	18
clothes	服装	19
star	明星	20
happy	搞笑	21

```

后续有新标签会逐步更新的



## 一、数据预处理

把未标注的数据格式处理成可以进行标注的格式 (数据预处理模式)

```
python weibo_dataProcess.py \
	--path='././data/Original_folder/'
```
参数说明:
path: 
按原始数据格式存放, 统一放在一个文件夹下
数据存放格式必须为csv文件,里面一定要包含两列 platform_cid(博主ID), blog_content(博主内容)

最终会在 data目录下生成 Dispose_folder文件夹 作为处理过待标注的csv数据
预处理后待标注的csv数据例子如下:

```
label	txt
0	这个动作一定要注意肩胛骨内收，先内收肩胛骨，再回拉手臂，顶点的时候想象背部夹住了一根绳子，实现念动一致孤立发力。
0	天才小画家们一起出慈善联名款
0	以及神秘却巨诱惑力的探险王国
0	超有意思，快来康康
0	决定明年开始不孤军奋战了，
0	杀人回忆凶手原型被抓
0	专门用来感谢亲爱滴铁粉小伙伴们，以及看着眼熟的粉丝（铁粉标识掉了的小伙伴莫慌，这主要赖我最近发博不够频繁）。
0	分享越多，朋友下单越多，你赚得越多！
```
--------------------------------------------------------------------------
## 二、模型训练工具
简述:
提供一个模型训练工具，根据标准的训练数据，可以训练出一个分类模型。
训练数据可以不断增加，方便迭代训练，提升模型得分；

使用命令行模式 `python run_classifier.py` 来训练模型，

训练参数如下：

```
python run_classifier.py \
	--sourcefile= ./data/Dispose_folder \
        --do_train=true \
	--do_eval=true \
	--do_predict=false \
	--model_name=BERT \
	--model_path=./chinese_L-12_H-768_A-12/ \
	--output_dir=./model_train/
```

参数说明:

sourcefile: 
标注好的数据文件统一放在一个文件夹下面,文件后缀为csv或tsv,
数据格式为: 有标题 两列 两个字段用Tab分割
do_train：
是否在训练集上训练模型
do_eval:
是否在验证集上验证模型
do_predict: 
是否在测试集上测试模型
model_name: 
BERT 或者 ALBERT 
model_path: 
如果为BERT模型的话 加载的模型路径为 chinese_L-12_H-768_A-12, 如果是ALBERT模型,加载预训练模型为:albert_tiny_zh
output_dir: 
最后输出模型的路径



sourcefile 数据格式 例子如下: 
```
label	txt
10	南方落雪
10	带着微博去旅行全球旅行攻略最炫打卡地【厦门自由行攻略】逛吃，逛吃，不避开这些坑的话逛不好、吃不爽
1	Keanna是中荷混血，做过模特，一直是谢和弦的忠实粉丝，陪他戒毒、治病，后来嫁给了他。
19	秋天第一波A字米色风衣 大姨妈出品的风衣口碑大家也都知道哦 洗水和版型是我最在意和考究的 包括里布的用料…
10	快闪，来吧小伙伴们，稻城亚丁欢迎你！稻城亚丁旅游攻略西藏旅游攻略 稻城亚丁小胡胡的秒拍视频
10	全球旅行攻略遇见美好 大西洋西岸巴哈马的沙滩，海，和动物们
10	全球旅行攻略不可辜负的美食【越南旅游攻略】人均000元的自由行一份街头河粉 一季越南夏天享受夏季的炙热与温柔久违法式风情的感动步步寻忘迹，有处特依依。
10	九寨沟旅游攻略看水必去九寨沟 10月有约的吗？
```



训练模型评价结果：

```
eval_accuracy = 0.850018
eval_f1 = 0.9229107
eval_loss = 0.71012884
eval_precision = 0.9198181
eval_recall = 0.9260241
global_step = 8330
loss = 0.7093687
```


## 三、标签提取工具
简述:
标签提取工具是一个命令行工具，按照要求的格式把每个博主的所有博文保存在一个文件中，
使用命令行可以对单个文件或者目录下的多个csv文件批量处理，提取出各个博主对应的热门标签；

标签提取命令行工具规划：labelPick.py
参数规划：
```
--top N 提取N个最热门标签
--path 文件夹   加载博主的数据路径,必须为csv格式
--out 文件名  输出标签提取的文件名路径
--model_preDir 此处加载训练好的模型(pb或ckpt)路径
```
使用样例：
```
python labelPick.py \
            --top=5 \
            --path=./blog_floder/ \
			--model_preDir=./model_predict/ \
			--out=./output/
```

参数说明:

```
--top N 提取N个最热门标签
--path 文件夹 里面的文件数据格式: 1. 必须包含  platform_cid(博主ID), blog_content(博主内容) 这两个字段 2.文件的后缀必须是以csv结尾的
--model_preDir : 此处存放训练好的pb或ckpt模型, 将得分最好的模型文件放到此文件夹下
--out 输出最终结果 样例下方有说明
```
###注意: model_preDir 此处放的时得分最好的ckpt或pb模型, 目前支持的是ckpt模型的批量预测, 将得分最好的ckpt模型放到此文件夹下
输出文件格式为：有标题行，一行一条记录,，用TAB分隔
输出文件样例如下：

```
blog_ID	Top-all	Top-k	time
博主ID	全部标签	服装,音乐,直播,美食,美妆	1585721976
博主ID	全部标签	明星,时尚,美妆,旅游,摄影	1585721976
```
###sh命令文件
```
我将这三个工具的命令都封装到 sh文件里面了, 以后可以直接运行sh文件
分别是:
m_process.sh :数据预处理工具
m_train_Albert.sh： 使用ALBert 模型训练工具
m_train_bert.sh: 使用Bert 模型训练工具
m_predict.sh: 标签提取工具
```

##模型我最后一次训练的数据情况

在验证集上的模型得分:
eval_accuracy = 0.850018
eval_f1 = 0.9229107
eval_loss = 0.71012884
eval_precision = 0.9198181
eval_recall = 0.9260241
global_step = 8330
loss = 0.7093687

验证集上模型混淆矩阵:

              precision    recall  f1-score   support

           0       0.91      0.90      0.91      1315
           1       0.87      0.92      0.89       429
           2       0.73      0.79      0.76        24
           3       0.87      0.80      0.83        50
           4       0.87      0.94      0.90        50
           5       0.00      0.00      0.00         7
           6       0.84      0.85      0.85       156
           7       0.92      0.89      0.90        74
           8       0.74      0.90      0.82        71
           9       0.89      0.83      0.86        90
          10       0.98      0.98      0.98      1924
          11       0.99      0.98      0.99       375
          12       0.95      0.94      0.95       229
          13       0.95      0.97      0.96        38
          14       0.00      0.00      0.00        25
          15       0.00      0.00      0.00         1
          16       0.91      0.92      0.91       252
          17       0.75      0.86      0.80         7
          19       0.94      0.97      0.95       432
          20       0.00      0.00      0.00         6

    accuracy                           0.93      5555
   macro avg       0.71      0.72      0.71      5555
weighted avg       0.93      0.93      0.93      5555

##后续的分数提高，依赖于标注数量的积累

以上操作均已封装成工具了, 默认的目录文件也加载完毕,



